{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worthy-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras.backend as K\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from PIL import Image\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-classroom",
   "metadata": {},
   "source": [
    "### Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frq = []\n",
    "frq = []\n",
    "word_frq = []\n",
    "sum_frq = 0\n",
    "with open(\"Datasets/meaningful_words_with_frq.csv\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        if len(row[0]) > 20: \n",
    "            continue\n",
    "        words_frq.append([row[0], int(row[1])])\n",
    "        frq.append(int(row[1]))\n",
    "        sum_frq += int(row[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frq.sort(key = lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfw = words_frq[:int(len(words_frq)/2)]\n",
    "lfw = words_frq[int(len(words_frq)/2):]\n",
    "highf_w = [item[0] for item in hfw]\n",
    "lowf_w = [item[0] for item in lfw]\n",
    "hf = frq[:int(len(words_frq)/2)]\n",
    "lf = frq[int(len(words_frq)/2):]\n",
    "ref = lf[0]\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-constitutional",
   "metadata": {},
   "source": [
    "## Multiply images by Frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir('ImageDataset/TrainSet/word/')\n",
    "trainwords = []\n",
    "trainwords_path = []\n",
    "for e in entries:\n",
    "    trainwords.append(e.split('_')[1].split('.')[0])\n",
    "    trainwords_path.append('ImageDataset/TrainSet/word/'+e)\n",
    "    \n",
    "entries = os.listdir('ImageDataset/TestSet/word/')\n",
    "testwords = []\n",
    "testwords_path = []\n",
    "for e in entries:\n",
    "    testwords.append(e.split('_')[1].split('.')[0])\n",
    "    testwords_path.append('ImageDataset/TestSet/word/'+e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-magnet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_extras = []\n",
    "hf_count = 0\n",
    "for w in tqdm(trainwords):\n",
    "    if w in highf_w:\n",
    "        hf_count += 1\n",
    "        index = highf_w.index(w)\n",
    "        f = hf[index]\n",
    "        num_extras.append(int((int(f/ref)-1)/70))\n",
    "        \n",
    "print(f\"# hf: {hf_count}  # lf: {len(trainwords)-hf_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in num_extras:\n",
    "    total+=i\n",
    "print(f\"Total number of extra images {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-vegetarian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train set\n",
    "pbar = tqdm(total = total)\n",
    "for w, p, n in tqdm(zip(trainwords, trainwords_path, num_extras)):\n",
    "    im1 = Image.open(p)\n",
    "    im2 = im1.copy()\n",
    "    new_path = p.split('.')[0]\n",
    "    for i in range(n):\n",
    "            im2.save(new_path+\".\"+str(i)+'.png', \"PNG\")\n",
    "    pbar.update(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-intervention",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fuzzy-volume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11876 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "batch_size = 32\n",
    "train_dataset = train.flow_from_directory(\"ImageDataset/TrainSet/\",\n",
    "                                          target_size=(30,150),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical')\n",
    "                                         \n",
    "test_dataset = test.flow_from_directory(\"ImageDataset/TestSet/\",\n",
    "                                          target_size=(30,150),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "packed-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonword': 0, 'word': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-dependence",
   "metadata": {},
   "source": [
    "### Network Structure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "irish-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:22:39.383874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-24 14:22:39.383900: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-24 14:22:39.383922: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mahvash-pc): /proc/driver/nvidia/version does not exist\n",
      "2021-12-24 14:22:39.384144: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(30,150,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(256,activation='relu'))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-queue",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "soviet-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 148, 32)       896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 36, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 36, 64)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 34, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 17, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4352)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1114368   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,208,130\n",
      "Trainable params: 1,208,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stone-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "372/372 [==============================] - 29s 76ms/step - loss: 0.5551 - accuracy: 0.6847 - val_loss: 0.4927 - val_accuracy: 0.7517\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 31s 84ms/step - loss: 0.3885 - accuracy: 0.8100 - val_loss: 0.3959 - val_accuracy: 0.8095\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 28s 76ms/step - loss: 0.3249 - accuracy: 0.8498 - val_loss: 0.3420 - val_accuracy: 0.8425\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 27s 72ms/step - loss: 0.2754 - accuracy: 0.8769 - val_loss: 0.3507 - val_accuracy: 0.8375\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 26s 71ms/step - loss: 0.2389 - accuracy: 0.8912 - val_loss: 0.3085 - val_accuracy: 0.8643\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 27s 72ms/step - loss: 0.2209 - accuracy: 0.9062 - val_loss: 0.3048 - val_accuracy: 0.8585\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 28s 76ms/step - loss: 0.1935 - accuracy: 0.9138 - val_loss: 0.3022 - val_accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 28s 74ms/step - loss: 0.1725 - accuracy: 0.9259 - val_loss: 0.2893 - val_accuracy: 0.8712\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 30s 80ms/step - loss: 0.1594 - accuracy: 0.9343 - val_loss: 0.3116 - val_accuracy: 0.8670\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 29s 78ms/step - loss: 0.1354 - accuracy: 0.9448 - val_loss: 0.3304 - val_accuracy: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7ba644070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "steps_per_epoch = len(train_dataset)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         steps_per_epoch = steps_per_epoch,\n",
    "         epochs = 10,\n",
    "         validation_data = test_dataset\n",
    "       \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce23683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:39:30.042276: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://fc937906-24e6-4cba-bd2e-25fd4912e5a3/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "outfile = open(\"check_points/CNN_model\",'wb')\n",
    "pickle.dump(model,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd66ba",
   "metadata": {},
   "source": [
    "## Train Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a40e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "entries = os.listdir('ImageDataset/TrainSet/nonword/')\n",
    "nonwords = []\n",
    "for e in entries:\n",
    "    nonwords.append(e)\n",
    "\n",
    "\n",
    "    \n",
    "entries = os.listdir('ImageDataset/TrainSet/word/')\n",
    "words = []\n",
    "for e in entries:\n",
    "    words.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06e576fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [03:12<00:00, 26.00it/s]\n"
     ]
    }
   ],
   "source": [
    "prob = []\n",
    "all_set = []\n",
    "for e in tqdm(nonwords):\n",
    "    word = (e.split('_'))[1].split('.')[0]\n",
    "    if word in all_set:\n",
    "        continue\n",
    "    all_set.append(word)\n",
    "    filename = \"ImageDataset/TrainSet/nonword/\" + e\n",
    "    img = image.load_img(filename,target_size=(30,150))\n",
    " \n",
    "    Y = image.img_to_array(img)\n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    X = X/255\n",
    "    val = model.predict(X)\n",
    "    prob.append([word, round(float(val[0][0]), 6), round(float(val[0][1]), 6),0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "618412d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6876/6876 [03:13<00:00, 35.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(words):\n",
    "    word = (e.split('_'))[1].split('.')[0]\n",
    "    if word in all_set:\n",
    "        continue\n",
    "    all_set.append(word)\n",
    "    filename = \"ImageDataset/TrainSet/word/\" + e\n",
    "    img = image.load_img(filename,target_size=(30,150))\n",
    " \n",
    "    Y = image.img_to_array(img)\n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    X = X/255\n",
    "    val = model.predict(X)\n",
    "    prob.append([word, round(float(val[0][0]), 6), round(float(val[0][1]), 6),1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cde3957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 336721.50it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Datasets/train_dataset_prob.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in tqdm(prob):\n",
    "        writer.writerow(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff032f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 485075.69it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Datasets/train_dataset_unique_words.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in tqdm(prob):\n",
    "        writer.writerow([k[0], k[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213c78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
