{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worthy-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-25 23:06:59.120041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-25 23:06:59.120127: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras.backend as K\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from PIL import Image\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-classroom",
   "metadata": {},
   "source": [
    "### Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disabled-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frq = []\n",
    "frq = []\n",
    "word_frq = []\n",
    "sum_frq = 0\n",
    "with open(\"Datasets/meaningful_words_with_frq.csv\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        if len(row[0]) > 20: \n",
    "            continue\n",
    "        words_frq.append([row[0], int(row[1])])\n",
    "        frq.append(int(row[1]))\n",
    "        sum_frq += int(row[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "circular-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frq.sort(key = lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polyphonic-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329153\n"
     ]
    }
   ],
   "source": [
    "hfw = words_frq[:int(len(words_frq)/2)]\n",
    "lfw = words_frq[int(len(words_frq)/2):]\n",
    "highf_w = [item[0] for item in hfw]\n",
    "lowf_w = [item[0] for item in lfw]\n",
    "hf = frq[:int(len(words_frq)/2)]\n",
    "lf = frq[int(len(words_frq)/2):]\n",
    "ref = lf[0]\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-constitutional",
   "metadata": {},
   "source": [
    "## Multiply images by Frq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4476f",
   "metadata": {},
   "source": [
    "Run this section only if you want to make extra images for hf words in your dataset for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir('ImageDataset/TrainSet/word/')\n",
    "trainwords = []\n",
    "trainwords_path = []\n",
    "for e in entries:\n",
    "    trainwords.append(e.split('_')[1].split('.')[0])\n",
    "    trainwords_path.append('ImageDataset/TrainSet/word/'+e)\n",
    "    \n",
    "entries = os.listdir('ImageDataset/TestSet/word/')\n",
    "testwords = []\n",
    "testwords_path = []\n",
    "for e in entries:\n",
    "    testwords.append(e.split('_')[1].split('.')[0])\n",
    "    testwords_path.append('ImageDataset/TestSet/word/'+e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-magnet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_extras = []\n",
    "hf_count = 0\n",
    "for w in tqdm(trainwords):\n",
    "    if w in highf_w:\n",
    "        hf_count += 1\n",
    "        index = highf_w.index(w)\n",
    "        f = hf[index]\n",
    "        num_extras.append(int((int(f/ref)-1)/70))\n",
    "        \n",
    "print(f\"# hf: {hf_count}  # lf: {len(trainwords)-hf_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in num_extras:\n",
    "    total+=i\n",
    "print(f\"Total number of extra images {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-vegetarian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train set\n",
    "pbar = tqdm(total = total)\n",
    "for w, p, n in tqdm(zip(trainwords, trainwords_path, num_extras)):\n",
    "    im1 = Image.open(p)\n",
    "    im2 = im1.copy()\n",
    "    new_path = p.split('.')[0]\n",
    "    for i in range(n):\n",
    "            im2.save(new_path+\".\"+str(i)+'.png', \"PNG\")\n",
    "    pbar.update(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-intervention",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fuzzy-volume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11876 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "batch_size = 32\n",
    "train_dataset = train.flow_from_directory(\"ImageDataset/TrainSet/\",\n",
    "                                          target_size=(30,150),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical')\n",
    "                                         \n",
    "test_dataset = test.flow_from_directory(\"ImageDataset/TestSet/\",\n",
    "                                          target_size=(30,150),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "packed-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonword': 0, 'word': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-dependence",
   "metadata": {},
   "source": [
    "### Network Structure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "irish-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(30,150,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64,activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(8,activation='relu'))\n",
    "\n",
    "# model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-queue",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "soviet-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 148, 32)       896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 74, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 12, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 6, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 36, 64)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 34, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 2, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4352)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               557184    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 659,226\n",
      "Trainable params: 659,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stone-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "372/372 [==============================] - 32s 86ms/step - loss: 0.5533 - accuracy: 0.6841 - val_loss: 0.4955 - val_accuracy: 0.7462\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 32s 85ms/step - loss: 0.3853 - accuracy: 0.8141 - val_loss: 0.3868 - val_accuracy: 0.8202\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 32s 86ms/step - loss: 0.3180 - accuracy: 0.8553 - val_loss: 0.3418 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 32s 87ms/step - loss: 0.2757 - accuracy: 0.8771 - val_loss: 0.3039 - val_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 32s 87ms/step - loss: 0.2412 - accuracy: 0.8911 - val_loss: 0.3056 - val_accuracy: 0.8565\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 32s 87ms/step - loss: 0.2135 - accuracy: 0.9051 - val_loss: 0.2848 - val_accuracy: 0.8758\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 33s 87ms/step - loss: 0.1856 - accuracy: 0.9202 - val_loss: 0.3058 - val_accuracy: 0.8615\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 33s 89ms/step - loss: 0.1775 - accuracy: 0.9249 - val_loss: 0.2903 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 33s 89ms/step - loss: 0.1523 - accuracy: 0.9355 - val_loss: 0.3140 - val_accuracy: 0.8773\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 35s 93ms/step - loss: 0.1377 - accuracy: 0.9422 - val_loss: 0.3014 - val_accuracy: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7785de460>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "steps_per_epoch = len(train_dataset)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         steps_per_epoch = steps_per_epoch,\n",
    "         epochs = 10,\n",
    "         validation_data = test_dataset\n",
    "       \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce23683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-25 23:41:30.330576: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6a08ce4b-4868-4d7a-8007-788b306a5421/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "outfile = open(\"check_points/CNN_model\",'wb')\n",
    "pickle.dump(model,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd66ba",
   "metadata": {},
   "source": [
    "## Train Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a40e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "entries = os.listdir('ImageDataset/TrainSet/nonword/')\n",
    "nonwords = []\n",
    "for e in entries:\n",
    "    nonwords.append(e)\n",
    "\n",
    "\n",
    "    \n",
    "entries = os.listdir('ImageDataset/TrainSet/word/')\n",
    "words = []\n",
    "for e in entries:\n",
    "    words.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e576fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [03:02<00:00, 27.38it/s]\n"
     ]
    }
   ],
   "source": [
    "prob = []\n",
    "all_set = []\n",
    "for e in tqdm(nonwords):\n",
    "    word = (e.split('_'))[1].split('.')[0]\n",
    "    if word in all_set:\n",
    "        continue\n",
    "    all_set.append(word)\n",
    "    filename = \"ImageDataset/TrainSet/nonword/\" + e\n",
    "    img = image.load_img(filename,target_size=(30,150))\n",
    " \n",
    "    Y = image.img_to_array(img)\n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    X = X/255\n",
    "    val = model.predict(X)\n",
    "    prob.append([word, round(float(val[0][0]), 6), round(float(val[0][1]), 6),0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "618412d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6876/6876 [03:04<00:00, 37.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(words):\n",
    "    word = (e.split('_'))[1].split('.')[0]\n",
    "    if word in all_set:\n",
    "        continue\n",
    "    all_set.append(word)\n",
    "    filename = \"ImageDataset/TrainSet/word/\" + e\n",
    "    img = image.load_img(filename,target_size=(30,150))\n",
    " \n",
    "    Y = image.img_to_array(img)\n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    X = X/255\n",
    "    val = model.predict(X)\n",
    "    prob.append([word, round(float(val[0][0]), 6), round(float(val[0][1]), 6),1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cde3957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 586402.71it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Datasets/train_dataset_prob.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in tqdm(prob):\n",
    "        writer.writerow(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff032f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 324556.15it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Datasets/train_dataset_unique_words.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in tqdm(prob):\n",
    "        writer.writerow([k[0], k[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213c78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
